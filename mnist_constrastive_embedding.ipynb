{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 58946\n",
      "    Root location: /lab/vislab/DATA/MNIST/training/\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=28, interpolation=PIL.Image.BILINEAR)\n",
      "               Grayscale(num_output_channels=1)\n",
      "               ToTensor()\n",
      "           )\n",
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "# images are 28x28\n",
    "transformations = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_set = datasets.ImageFolder(\"/lab/vislab/DATA/MNIST/training/\", transform = transformations)\n",
    "val_set = datasets.ImageFolder(\"/lab/vislab/DATA/MNIST/testing/\", transform = transformations)\n",
    "print(train_set)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size =32, shuffle=True)\n",
    "\n",
    "# torch.nn.TripletMarginLoss(margin=1.0, p=2.0, eps=1e-06, swap=False, \n",
    "# size_average=None, reduce=None, reduction='mean')\n",
    "# output = criterion(anchor, positive, negative)\n",
    "criterion = MyTripletLoss() \n",
    "\n",
    "# Connector to GPU\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', device)\n",
    "\n",
    "\n",
    "# Sqaure size of each training image\n",
    "img_size = 28\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 10\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_(nn.Module):\n",
    "    \"\"\"Basic model for this set. Any changes or suggestions are welcome\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model_, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):  \n",
    "        # conv 1  \n",
    "        t = self.conv1(t)  \n",
    "        t = F.relu(t)  \n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)   \n",
    "        # conv 2  \n",
    "        t = self.conv2(t)   \n",
    "        t = F.relu(t)  \n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)   \n",
    "        # fc1   \n",
    "        t = t.reshape(-1, 12*4*4)  \n",
    "        t = self.fc1(t)  \n",
    "        t = F.relu(t)   \n",
    "        # fc2  \n",
    "        t = self.fc2(t)  \n",
    "        t = F.relu(t)  \n",
    "        # output  \n",
    "        t = self.out(t)  \n",
    "        # don't need softmax here since we'll use cross-entropy as activation.   \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTripletLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyTripletLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs, labels):\n",
    "        # so inputs and labels are matrices\n",
    "        losses = []\n",
    "        batch_loss = 0.0\n",
    "        # assume inputs and labels are same length\n",
    "        \n",
    "        for idx, anchor in enumerate(inputs): \n",
    "            positive = random.choice([image_ for i, image_ in enumerate(inputs) if labels[i] == labels[idx]])\n",
    "            negative = random.choice([image_ for i, image_ in enumerate(inputs) if labels[i] != labels[idx]])\n",
    "            \n",
    "            # safety of deep copy\n",
    "            a1 = anchor.clone().detach()\n",
    "            a2 = anchor.clone().detach()\n",
    "\n",
    "            dist1 = a1.sub(positive)    \n",
    "            dist2 = a2.sub(negative)\n",
    "            dist1 = dist1**2\n",
    "            dist2 = dist2**2\n",
    "            loss = max(dist1 - dist2 + 0.01)\n",
    "\n",
    "            losses.append(loss)\n",
    "        \n",
    "        batch_loss = max(losses)\n",
    "        return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, num_epochs):\n",
    "    \"\"\"Bodied function to train data to network\"\"\"\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    loss = 0.0    \n",
    "    # sampler = torch.utils.data.RandomSampler(train_set, replacement=False, num_samples=1)\n",
    "    # eval for train and test, use criterion and back propagation, specific towards\n",
    "    # the type of loss that we want, contrastive\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch num: \", epoch)   \n",
    "        model.train()\n",
    "        for idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model.forward(inputs)\n",
    "          \n",
    "            loss = criterion(output, labels)\n",
    "            loss = Variable(loss, requires_grad = True)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()*inputs.size(0)\n",
    "            \n",
    "        print(\"loss for the epoch is:\", train_loss)\n",
    "        model.eval()\n",
    "        val_loss = 0 \n",
    "        accuracy = 0\n",
    "        counter = 0 \n",
    "        with torch.no_grad():\n",
    "\n",
    "            for inputs, labels in val_loader:\n",
    "                # Move to device\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                # Forward pass\n",
    "                output = model.forward(inputs)\n",
    "                # Calculate Loss\n",
    "            \n",
    "                valloss = criterion(inputs, labels)\n",
    "                \n",
    "                \n",
    "\n",
    "                # ******* THIS PART WAS FOUND ONLINE *********\n",
    "                #\n",
    "                #\n",
    "                # Add loss to the validation set's running loss\n",
    "                val_loss += valloss.item()*inputs.size(0)\n",
    "\n",
    "                # Since our model outputs a LogSoftmax, find the real \n",
    "                # percentages by reversing the log function\n",
    "                output = torch.exp(output)\n",
    "                # Get the top class of the output\n",
    "                top_p, top_class = output.topk(1, dim=1)\n",
    "                # See how many of the classes were correct?\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                # Calculate the mean (get the accuracy for this batch)\n",
    "                # and add it to the running accuracy for this epoch\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "                # Print the progress of our evaluation\n",
    "                counter += 1\n",
    "                print(counter, \"/\", len(val_loader))\n",
    "                #\n",
    "                #\n",
    "                #\n",
    "                # **********************************************\n",
    "            \n",
    "    return model, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin to train model ...\n",
      "Epoch num:  0\n"
     ]
    }
   ],
   "source": [
    "# Run time script\n",
    "model = Model_()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "print(\"Begin to train model ...\")\n",
    "\n",
    "result, loss = train_model(model, optimizer, num_epochs)\n",
    "print(\"Done training model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO set up some graphs and visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
