{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images are 28x28\n",
    "# each row in the np imgs is 784-long\n",
    "imgs, labels = loadlocal_mnist(\n",
    "        images_path='/lab/vislab/DATA/just/mnist/train-images-idx3-ubyte', \n",
    "        labels_path='/lab/vislab/DATA/just/mnist/train-labels-idx1-ubyte')\n",
    "\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 60\n",
    "\n",
    "# Type of Loss\n",
    "criterion = nn.CrossEntropyLoss() # crucial math\n",
    "\n",
    "# Sqaure size of each training image\n",
    "img_size = 28\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 10\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelResNet18(nn.Module):\n",
    "    \"\"\"Basic ResNet18 model for this set. Any changes or suggestions are welcome\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ModelResNet18, self).__init__()\n",
    "\n",
    "        mod=models.resnet18(pretrained=False)\n",
    "        self.model = nn.Sequential(\n",
    "            mod.conv1,\n",
    "            mod.bn1,\n",
    "            mod.relu,\n",
    "            mod.maxpool,\n",
    "\n",
    "            mod.layer1,\n",
    "            mod.layer2,\n",
    "            mod.layer3,\n",
    "            mod.layer4,\n",
    "        ).to(\"cuda:0\")\n",
    "                        # input,    output\n",
    "        self.fc=nn.Linear(img_size, num_classes).to('cuda:0')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward propogation between lateral layers of the network\"\"\"\n",
    "        \n",
    "        x=x.transpose(1,0)\n",
    "        x0=x[:-1].transpose(1,0)\n",
    "        x1=x[-1]\n",
    "        bs, ncrops, c, h, w = x0.size()\n",
    "        x0=x0.contiguous().view((-1, c, h, w))\n",
    "        x0 = self.model(x0.to('cuda:0'))\n",
    "        x0 = F.avg_pool2d(x0, 8)\n",
    "        x0,_ = torch.max(x0.view(bs, ncrops, -1),1)\n",
    "        x0=x0.to('cuda:0')\n",
    "        if self.training==True:\n",
    "            x=F.dropout(x,0.4)\n",
    "        return self.fc(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, imgs, labels, img_size, num_classes, num_epochs):\n",
    "    \"\"\"Bodied function to train data to network\"\"\"\n",
    "\n",
    "    # eval for train and test, use criterion and back propagation, specific towards\n",
    "    # the type of loss that we want, contrastive\n",
    "    \n",
    "    \n",
    "    # important steps\n",
    "                        # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step(\n",
    "\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
